(window.webpackJsonp=window.webpackJsonp||[]).push([[2],{259:function(e,t,n){var content=n(263);content.__esModule&&(content=content.default),"string"==typeof content&&(content=[[e.i,content,""]]),content.locals&&(e.exports=content.locals);(0,n(74).default)("55fefe77",content,!0,{sourceMap:!1})},262:function(e,t,n){"use strict";n(259)},263:function(e,t,n){var l=n(73)(!1);l.push([e.i,"ol[data-v-81ccf2ec],ul[data-v-81ccf2ec]{margin-left:.5em}ul[data-v-81ccf2ec]{list-style-type:none}",""]),e.exports=l},269:function(e,t,n){"use strict";n.r(t);n(262);var l=n(27),component=Object(l.a)({},(function(){this._self._c;return this._m(0)}),[function(){var e=this,t=e._self._c;return t("div",[t("ol",{attrs:{reversed:""}},[t("li",[t("ul",[t("li",[t("b",[e._v("\n            A Context-aware Knowledge Transferring Strategy for CTC-based\n            ASR\n          ")])]),e._v(" "),t("li",[t("u",[e._v("Ke-Han Lu")]),e._v(" and Kuan-Yu Chen\n        ")]),e._v(" "),t("li",[e._v("IEEE Spoken Language Technology Workshop (SLT 2022)SLT 2022")]),e._v(" "),t("li",[t("a",{staticClass:"tag is-info is-light",attrs:{href:"https://arxiv.org/abs/2210.06244"}},[e._v("Paper")]),e._v(" "),t("a",{staticClass:"tag is-info is-light",attrs:{href:"https://github.com/kehanlu/Mandarin-Wav2Vec2"}},[e._v("GitHub")])])])]),e._v(" "),t("li",[t("ul",[t("li",[t("b",[e._v("Non-autoregressive ASR Modeling using Pre-trained Language Models for Chinese Speech Recognition")])]),e._v(" "),t("li",[e._v("\n          Fu-Hao Yu, Kuan-Yu Chen, and\n          "),t("u",[e._v("Ke-Han Lu")])]),e._v(" "),t("li",[e._v("IEEE/ACM Transactions on Audio, Speech, and Language Processing")]),e._v(" "),t("li",[t("a",{staticClass:"tag is-info is-light",attrs:{href:"https://ieeexplore.ieee.org/document/9755057/"}},[e._v("Paper")])])])]),e._v(" "),t("li",[t("ul",[t("li",[t("b",[e._v("A Transformer-based Cross-modal Fusion Model with Adversarial Training for VQA Challenge 2021")])]),e._v(" "),t("li",[t("u",[e._v("Ke-Han Lu")]),e._v(", Bo-Han Fang and Kuan-Yu Chen\n        ")]),e._v(" "),t("li",[e._v("Poster spotlight, VQA workshop, CVPR 2021")]),e._v(" "),t("li",[t("a",{staticClass:"tag is-info is-light",attrs:{href:"https://arxiv.org/abs/2106.13033"}},[e._v("Paper")]),e._v(" "),t("a",{staticClass:"tag is-info is-light",attrs:{href:"https://visualqa.org/roe.html"}},[e._v("Leaderboard")]),e._v(" "),t("a",{staticClass:"tag is-info is-light",attrs:{href:"https://youtu.be/dYeS8T19ves"}},[e._v("Video")])])])]),e._v(" "),t("li",[t("ul",[t("li",[t("b",[e._v("ntust-nlp-2 at ROCLING-2021 Shared Task: BERT-based semantic analyzer with word-level information")])]),e._v(" "),t("li",[t("u",[e._v("Ke-Han Lu")]),e._v(" and Kuan-Yu Chen\n        ")]),e._v(" "),t("li",[e._v("ROCLING 2021: Conference on Computational Linguistics and Speech Processing")]),e._v(" "),t("li",[t("a",{staticClass:"tag is-info is-light",attrs:{href:"https://aclanthology.org/2021.rocling-1.47.pdf"}},[e._v("Paper")])])])]),e._v(" "),t("li",[t("ul",[t("li",[t("b",[e._v("A Preliminary Study of Formosa Speech Recognition Challenge 2020 â€“ Taiwanese ASR")])]),e._v(" "),t("li",[e._v("\n          Fu-Hao Yu,\n          "),t("u",[e._v("Ke-Han Lu")]),e._v("\n          , Yi-Wei Wang, Wei-Zhe Chang, Wei-Kai Huang and Kuan-Yu Chen\n        ")]),e._v(" "),t("li",[e._v("International Journal of Computational Linguistics and Chinese Language Processing")]),e._v(" "),t("li",[t("a",{staticClass:"tag is-info is-light",attrs:{href:"https://aclanthology.org/2021.ijclclp-1.3.pdf"}},[e._v("Paper")])])])])])])}],!1,null,"81ccf2ec",null);t.default=component.exports}}]);